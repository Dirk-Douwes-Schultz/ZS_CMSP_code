dnbinom(x=6,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==7)/length(y)
rm(list=ls())
library(MASS)
nsims <- 1000000
lambda <- 5
r <- 1
p <- .15
x <- rnbinom(n=nsims,size = r,prob = r/(r+lambda))
mean(x)
var(x)
lambda*(1+lambda/r)
x <- x[x>0]
y <- rbinom(n=length(x),size = x,prob = p)
hist(y)
mean(y)
mean(x)*p
var(y)
sum(y==0)/length(y)
#fit a negative binomial to y
fit <- glm.nb(formula = y~1)
fit$coefficients[[1]]
fit$theta
lambda_nb_fitted <- exp(fit$coefficients[[1]])
r_nb_fitted <- fit$theta
#compare fitted distributions
(r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))^(r_nb_fitted)
sum(y==0)/length(y)
dnbinom(x=1,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==1)/length(y)
dnbinom(x=2,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==2)/length(y)
dnbinom(x=3,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==3)/length(y)
dnbinom(x=4,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==4)/length(y)
dnbinom(x=5,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==5)/length(y)
dnbinom(x=6,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==7)/length(y)
rm(list=ls())
library(MASS)
nsims <- 1000000
lambda <- 5
r <- .5
p <- .15
x <- rnbinom(n=nsims,size = r,prob = r/(r+lambda))
mean(x)
var(x)
lambda*(1+lambda/r)
x <- x[x>0]
y <- rbinom(n=length(x),size = x,prob = p)
hist(y)
mean(y)
mean(x)*p
var(y)
sum(y==0)/length(y)
#fit a negative binomial to y
fit <- glm.nb(formula = y~1)
fit$coefficients[[1]]
fit$theta
lambda_nb_fitted <- exp(fit$coefficients[[1]])
r_nb_fitted <- fit$theta
#compare fitted distributions
(r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))^(r_nb_fitted)
sum(y==0)/length(y)
dnbinom(x=1,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==1)/length(y)
dnbinom(x=2,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==2)/length(y)
dnbinom(x=3,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==3)/length(y)
dnbinom(x=4,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==4)/length(y)
dnbinom(x=5,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==5)/length(y)
dnbinom(x=6,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==7)/length(y)
rm(list=ls())
library(MASS)
nsims <- 1000000
lambda <- 5
r <- 2
p <- .15
x <- rnbinom(n=nsims,size = r,prob = r/(r+lambda))
mean(x)
var(x)
lambda*(1+lambda/r)
x <- x[x>0]
y <- rbinom(n=length(x),size = x,prob = p)
hist(y)
mean(y)
mean(x)*p
var(y)
sum(y==0)/length(y)
#fit a negative binomial to y
fit <- glm.nb(formula = y~1)
fit$coefficients[[1]]
fit$theta
lambda_nb_fitted <- exp(fit$coefficients[[1]])
r_nb_fitted <- fit$theta
#compare fitted distributions
(r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))^(r_nb_fitted)
sum(y==0)/length(y)
rm(list=ls())
library(MASS)
nsims <- 1000000
lambda <- 10
r <- 2
p <- .2
x <- rnbinom(n=nsims,size = r,prob = r/(r+lambda))
mean(x)
var(x)
lambda*(1+lambda/r)
x <- x[x>0]
y <- rbinom(n=length(x),size = x,prob = p)
hist(y)
mean(y)
mean(x)*p
var(y)
sum(y==0)/length(y)
#fit a negative binomial to y
fit <- glm.nb(formula = y~1)
fit$coefficients[[1]]
fit$theta
lambda_nb_fitted <- exp(fit$coefficients[[1]])
r_nb_fitted <- fit$theta
#compare fitted distributions
(r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))^(r_nb_fitted)
sum(y==0)/length(y)
dnbinom(x=1,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==1)/length(y)
dnbinom(x=2,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==2)/length(y)
dnbinom(x=3,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==3)/length(y)
dnbinom(x=4,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==4)/length(y)
dnbinom(x=5,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==5)/length(y)
dnbinom(x=6,size = r_nb_fitted,prob=r_nb_fitted/(r_nb_fitted+lambda_nb_fitted))
sum(y==7)/length(y)
## beginning of R Code
rm(list=ls())
par(mfrow=c(2,2))
nsim <- 100000
p <- 7
## even more extreme results for p <- 14
kappa <- runif(nsim)
#kappa <- rep(.5,nsim)
#q <- rgamma(nsim, .1, .1)
#q <- runif(nsim,min=0,max=10)
q1 <- runif(nsim,min=0,max=1)
q <- rep(NA,nsim)
L <- 10
for(i in 1:nsim){
if(q1[i]<(1/p)){
q[i] <- runif(n=1,min=0,max=1)
}else if(q1[i]>(1/p)&q1[i]<((p-1)/p)){
q[i] <- runif(n=1,min=1,max=p)
}else{
q[i] <- runif(n=1,min=p,max=L)
}
}
hist(q)
#q <- rep(1,nsim)
d <- seq(1, p, 1)
logomega <- matrix(NA, nrow=nsim, ncol=length(d))
for(i in 1:length(d)){
logomega[,i] <- lgamma(d[i]-1+q)-lgamma(q)-lgamma(d[i])+q*log(1-kappa)+(d[i]-1)*log(kappa)
}
omega <- exp(logomega)
omegasum <- apply(omega, 1, sum)
omega <- omega/matrix(omegasum, nrow=nsim, ncol=length(d), byrow=FALSE)
print(omegamean <- apply(omega, 2, mean))
plot(omegamean, pch=19,ylim=c(0,1))
abline(h=1/p)
q <- rgamma(nsim, .1, .1)
hist(q,xlim=c(0,20))
p <- 7
## even more extreme results for p <- 14
d <- seq(1, p, 1)
logomega <- matrix(NA, nrow=nsim, ncol=length(d))
for(i in 1:length(d)){
logomega[,i] <- lgamma(d[i]-1+q)-lgamma(q)
-lgamma(d[i])+q*log(1-kappa)+(d[i]-1)*log(kappa)
}
omega <- exp(logomega)
omegasum <- apply(omega, 1, sum)
omega <- omega/matrix(omegasum, nrow=nsim, ncol=length(d), byrow=FALSE)
print(omegamean <- apply(omega, 2, mean))
plot(omegamean, pch=19,ylim=c(0,1))
abline(h=1/p)
## beginning of R Code
rm(list=ls())
par(mfrow=c(2,2))
nsim <- 100000
p <- 7
## even more extreme results for p <- 14
kappa <- runif(nsim)
#kappa <- rep(.5,nsim)
#q <- rgamma(nsim, .1, .1)
#q <- runif(nsim,min=0,max=10)
q1 <- runif(nsim,min=0,max=1)
q <- rep(NA,nsim)
L <- 10
for(i in 1:nsim){
if(q1[i]<(1/p)){
q[i] <- runif(n=1,min=0,max=1)
}else if(q1[i]>(1/p)&q1[i]<((p-1)/p)){
q[i] <- runif(n=1,min=1,max=p)
}else{
q[i] <- runif(n=1,min=p,max=L)
}
}
hist(q,freq=FALSE, main="mixunif prior")
#q <- rep(1,nsim)
d <- seq(1, p, 1)
logomega <- matrix(NA, nrow=nsim, ncol=length(d))
for(i in 1:length(d)){
logomega[,i] <- lgamma(d[i]-1+q)-lgamma(q)-lgamma(d[i])+q*log(1-kappa)+(d[i]-1)*log(kappa)
}
omega <- exp(logomega)
omegasum <- apply(omega, 1, sum)
omega <- omega/matrix(omegasum, nrow=nsim, ncol=length(d), byrow=FALSE)
print(omegamean <- apply(omega, 2, mean))
plot(omegamean, pch=19,ylim=c(0,1))
abline(h=1/p)
quantile(omega[,7],probs=c(.025,.975))
quantile(omega[,1],probs=c(.025,.975))
quantile(omega[,2],probs=c(.025,.975))
quantile(omega[,3],probs=c(.025,.975))
quantile(omega[,4],probs=c(.025,.975))
quantile(omega[,5],probs=c(.025,.975))
quantile(omega[,6],probs=c(.025,.975))
q <- rgamma(nsim, .1, .1)
hist(q,xlim=c(0,20),freq=FALSE,main="gamma prior")
p <- 7
## even more extreme results for p <- 14
d <- seq(1, p, 1)
logomega <- matrix(NA, nrow=nsim, ncol=length(d))
for(i in 1:length(d)){
logomega[,i] <- lgamma(d[i]-1+q)-lgamma(q)
-lgamma(d[i])+q*log(1-kappa)+(d[i]-1)*log(kappa)
}
omega <- exp(logomega)
omegasum <- apply(omega, 1, sum)
omega <- omega/matrix(omegasum, nrow=nsim, ncol=length(d), byrow=FALSE)
print(omegamean <- apply(omega, 2, mean))
plot(omegamean, pch=19,ylim=c(0,1))
abline(h=1/p)
## best fitting (bolded in Table 1) ZS-CMSNB model from Table 1 of the main text with
#bFFBS2 samplers for the hidden states
rm(list=ls())
library(nimble)
memory.limit(size=1E10)
setwd("~/GitHub/ZS_CMSP_code")
#bring in cleaned data
load("final_data_cleaned.Rdata")
#cases_it=y_it
cases <-dnew2[,10:93]
cases <- as.matrix(cases)
plot(cases[1,])
#Rain_t
Rain <- d$TotPrec[1:84]
#Temp_t
Temp <- d$MeanMaxTemp[1:84]
#HDI_i
HDI <- dnew2$HDI
#N_i
N <- dnew2$Npop
#population in thousands
pop <- N/1000
#construct neighborhood matrix
N_matrix <- is_connect_nei
colnames(N_matrix) <- c("CodDistrict.y",paste0("V",N_matrix$CodDistrict))
N_matrix <- N_matrix[order(N_matrix$CodDistrict.y),]
N_matrix <- N_matrix[,c("CodDistrict.y",paste0("V",1:12),paste0("V",14:161))]
#check symmetric
sum(N_matrix[1:160,2:161] != t(N_matrix[1:160,2:161]))
N_matrix <- N_matrix[1:160,2:161]
#its good
sum(N_matrix[1:160,1:160] != t(N_matrix[1:160,1:160]))
min(rowSums(N_matrix))
#symmetric and every location has at least one neighbor
NM <- as.matrix(N_matrix)
#make a count vector
count <- rep(NA,160)
num <- as.numeric(as.carAdjacency(N_matrix)$num)
count[1] <- 1
for(i in 1:159){
count[i+1]  <- count[i]+num[i]
}
#also need S_it=NA if y_it=0 and S_it=1 if y_it>0
S <- matrix(nrow=160,ncol=84)
for(i in 1:160){
for(t in 1:84){
if(cases[i,t]>0){
S[i,t] <- 1
}
}
}
#now calc prior mean/sd of log(r_i), see notes (from Bauer 2018 paper)
theta1 <- .5
theta2 <- 4
lru <- rep(NA,160)
lrsd <- rep(NA,160)
for(i in 1:160){
lru[i] <- log(mean(cases[i,]))-log(theta1)
lrsd[i] <- log(theta1/theta2)/(-1.64)
}
lru[lru==-Inf] <- min(lru[lru!=-Inf])
#sum cases in neighboring areas
log_sum_nei_cases <- matrix(nrow=160,ncol=84)
for(i in 1:160){
for(t in 2:84){
nei <- which(N_matrix[i,]==1)
log_sum_nei_cases[i,t] <- 0
for(j in nei){
log_sum_nei_cases[i,t] <- log_sum_nei_cases[i,t]+log(cases[j,t-1]+1)
}
}
}
hist(log_sum_nei_cases)
mean_log_sum_nei_cases <- mean(log_sum_nei_cases,na.rm = TRUE)
#sum of prevalence in neighboring areas
log_sum_nei_prev <- matrix(nrow=160,ncol=84)
for(i in 1:160){
for(t in 2:84){
nei <- which(N_matrix[i,]==1)
log_sum_nei_prev[i,t] <- 0
for(j in nei){
log_sum_nei_prev[i,t] <- log_sum_nei_prev[i,t]+log((cases[j,t-1]/pop[j])+1)
}
}
}
hist(log_sum_nei_prev)
mean_log_sum_nei_prev <- mean(log_sum_nei_prev,na.rm = TRUE)
#need to calculate log of prevalence
prev <- matrix(nrow = 160,ncol=84)
for(i in 1:160){
for(t in 1:84){
prev[i,t] <- cases[i,t]/pop[i]
}
}
hist(log(prev+1))
dengeeConsts <- list(N=160,T=84,adj=as.numeric(as.carAdjacency(N_matrix)$adj),
num=as.numeric(as.carAdjacency(N_matrix)$num),
pop=pop,Temp=Temp,Rain=Rain,HDI=HDI,
count=count,psi =cases,mpsi=mean(cases),lpsi=log(cases+1),
mlpsi=mean(log(cases+1)),lprev = log(prev+1),mlprev=mean(log(prev+1)),
lru=lru,lrsd=lrsd,
log_sum_nei_cases=log_sum_nei_cases,
mean_log_sum_nei_cases=mean_log_sum_nei_cases,
log_sum_nei_prev=log_sum_nei_prev,
mean_log_sum_nei_prev=mean_log_sum_nei_prev)
dengeeData <- list(y=cases,S=S)
dengeeCode <- nimbleCode({
#priors
beta0 ~ dnorm(0,sd=100)
beta1 ~dnorm(0,sd=100)
beta2 ~ dnorm(0, sd=100)
rho~dnorm(0,sd=100)
for(j in 1:15){
alpha[j]~dnorm(0,sd=100)
}
for(i in 1:N){
b0[i]~dnorm(beta0,prec_b0)
b[i]~dnorm(rho,sd=sigma_b)
}
sigma_b ~ dunif(0,10)
prec_b0 ~ dgamma(.1,.1)
sigma_b0 <- 1/sqrt(prec_b0)
for(i in 1:160){
r[i] <- exp(lr[i])
lr[i] ~ dnorm(lru[i],sd=lrsd[i])
}
#likelihood
for(i in 1:N) {
for(t in 2:T){
mup[i,t] <- exp(b0[i]+beta1*(Rain[t-1]-mean(Rain[]))+
beta2*(Temp[t-1]-mean(Temp[])))*psi[i,t-1]+exp(b[i])
p[i,t] <- r[i]/(r[i]+(S[i,t])*mup[i,t]) - 1e-10*(1-S[i,t])
y[i,t] ~ dnegbin(p[i,t],r[i])
}
}
#markov chain
for(i in 1:N) {
S[i,1] ~ dbern(.5)
for(t in 2:T){
#calc Neighbor Sum for t=t-1
Snei[num[i],i,(t-1)] <- S[adj[count[i]],(t-1)]
for(j in 2:num[i]){
Snei[num[i]-j+1,i,(t-1)] <- Snei[num[i]-j+2,i,(t-1)] + S[adj[count[i]+j-1],(t-1)]
}
#calc Neighbor Sum pop for t=t-1
Snei_pop[num[i],i,(t-1)] <- S[adj[count[i]],(t-1)]*log(pop[adj[count[i]]]*pop[i])
for(j in 2:num[i]){
Snei_pop[num[i]-j+1,i,(t-1)] <- Snei_pop[num[i]-j+2,i,(t-1)] + S[adj[count[i]+j-1],(t-1)]*log(pop[adj[count[i]+j-1]]*pop[i])
}
lp01[i,t] <- alpha[1]+alpha[2]*(pop[i]-mean(pop[]))+alpha[3]*(HDI[i]-mean(HDI[]))+
alpha[4]*(Temp[t-1]-mean(Temp[]))+alpha[5]*(Rain[t-1]-mean(Rain[]))+
alpha[6]*Snei[1,i,(t-1)]+alpha[14]*(log_sum_nei_prev[i,t]-mean_log_sum_nei_prev)+
alpha[15]*Snei_pop[1,i,(t-1)]
lp11[i,t] <- alpha[7]+alpha[8]*(pop[i]-mean(pop[]))+
alpha[9]*(HDI[i]-mean(HDI[]))+alpha[10]*(Temp[t-1]-mean(Temp[]))+
alpha[11]*(Rain[t-1]-mean(Rain[]))+alpha[12]*Snei[1,i,(t-1)]+
alpha[13]*(lpsi[i,t-1]-mlpsi)
logit(p1[i,t]) <- lp01[i,t]*(1-S[i,t-1])+lp11[i,t]*S[i,t-1]
S[i,t] ~ dbern(p1[i,t])
}
}
})
inits <- list(beta0 = rnorm(n=1,mean=0,sd=1),beta1 = rnorm(n=1,mean=0,sd=.01),
beta2 = rnorm(n=1,mean=0,sd=.01) ,
sigma_b = .01,prec_b0 = 1,rho=rnorm(n=1,mean=0,sd=1) ,
S=matrix(rep(0,160*84),nrow = 160,ncol=84),
alpha=rnorm(n=15,mean=0,sd=c(1,.01,1,.1,.01,.1,.1,.01,1,.1,.01,.1,.01,.01,.01)),
b=rnorm(n=160,mean=0,sd=.01),b0=rnorm(n=160,mean=0,sd=.01),
lr=runif(n=160,min=-10,max=10))
dengeemodel <- nimbleModel(dengeeCode, dengeeConsts, dengeeData, inits)
Cdengee <- compileNimble(dengeemodel)
#bring in the custom samplers
source("~/GitHub/coupled_models/coupled_NB_samplers.R")
dengeeConf <- configureMCMC(dengeemodel, print = TRUE)
#need to create a list of blocks
#first find locations with all positive values that dont need to be blocked
g0 <- NULL
for(i in 1:160){
if(sum(as.numeric(cases[i,]>0))==84){
g0 <- c(g0,i)
}
}
#block neighbors together
nei_block <- min(which(N_matrix[1,]==1))
block_list <- list(c(1,nei_block))
for(i in 2:160){
if(!i %in% unlist(block_list)& !i %in% g0){
for(j in which(N_matrix[i,]==1)){
if(!j %in% unlist(block_list)& !j %in% g0){
block_list <- append(block_list,list(c(i,j)))
break
}
}
}
}
#this procedure leaves some areas without neighbors to block
#we put them in single location blocks
for(i in 1:160){
if(!i %in% unlist(block_list)& !i %in% g0){
block_list <- append(block_list,list(c(i)))
}
}
#checks, should be 157, 71 2 loc blocks,
#15 locs sampled in one block and
#3 locs do not need to be sampled as all >0
length(unique(unlist(block_list)))
#add bFFBS2 sampler to 2 location blocks
#assign iFFBS sampler to 1 location blocks
#this may not work in newer versions of Nimble
for(i in 1:length(block_list)){
block <- block_list[[i]]
if(length(block)==2){
loc1 <- block[1]
loc2 <- block[2]
dq1 <- !dengeemodel$isData(paste0("S[",loc1,", ]"))
dq2 <- !dengeemodel$isData(paste0("S[",loc2,", ]"))
if(sum(dq1)>0 & sum(dq2)>0){
dengeeConf$removeSampler(c(paste0("S[",loc1,", dq1]"),paste0("S[",loc2,", dq2]")))
dengeeConf$addSampler(target = dengeemodel$expandNodeNames(c(paste0("S[",loc1,", dq1]"),paste0("S[",loc2,", dq2]"))),
type = "bZIPFFBS2")
}else{
print("error: you have a empty loc block")
}
}else{
loc <- block[1]
dq <- !dengeemodel$isData(paste0("S[",loc,", ]"))
if(sum(dq)>0){
dengeeConf$removeSampler(paste0("S[",loc,", dq]"))
dengeeConf$addSampler(target = dengeemodel$expandNodeNames(paste0("S[",loc,", dq]")),
type = "iZIPFFBS4")
}else{
print("error: you have a empty loc block")
}
}
}
dengeeConf
#try a RW block sampler
dengeeConf$removeSampler(c("alpha[1]","alpha[6]","alpha[7]","alpha[12]","alpha[2]","alpha[14]","alpha[15]"))
dengeeConf$addSampler(target = c("alpha[1]","alpha[6]","alpha[2]","alpha[14]","alpha[15]"),type = "AF_slice")
dengeeConf$addSampler(target = c("alpha[7]","alpha[12]"),type = "AF_slice")
#sample sd on log scale
dengeeConf$removeSampler(c("sigma_b"))
dengeeConf$addSampler(target=c("sigma_b"),type="RW",control=list(log=TRUE))
print(dengeeConf)
dengeeConf$addMonitors(c("beta0","rho" ,"b","sigma_b","alpha","beta1","beta2","r","b0","sigma_b0"))
dengeeMCMC <- buildMCMC(dengeeConf)
CdengeeMCMC <- compileNimble(dengeeMCMC, project = dengeemodel,resetFunctions = TRUE)
initsFunction <- function() list(beta0 = rnorm(n=1,mean=0,sd=1),beta1 = rnorm(n=1,mean=0,sd=.01),
beta2 = rnorm(n=1,mean=0,sd=.01) ,
sigma_b = .01,prec_b0 = 1,rho=rnorm(n=1,mean=0,sd=1) ,
S=matrix(rep(0,160*84),nrow = 160,ncol=84),
alpha=rnorm(n=15,mean=0,sd=c(1,.01,1,.1,.01,.1,.1,.01,1,.1,.01,.1,.01,.01,.01)),
b=rnorm(n=160,mean=0,sd=.01),b0=rnorm(n=160,mean=0,sd=.01),
lr=runif(n=160,min=-10,max=10))
start_time <- Sys.time()
samples <- runMCMC(CdengeeMCMC, niter = 80000,nchains = 1,nburnin=30000
,samplesAsCodaMCMC = TRUE,thin=5,inits = initsFunction)
end_time <- Sys.time()
end_time - start_time
run_time <- end_time-start_time
save(samples,file="C:/Users/dirkd/OneDrive/Documents/JRSS_revision/results/ZS_CMSNB_bFFBS_github.RData")
